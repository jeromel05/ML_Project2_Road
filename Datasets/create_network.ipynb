{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "base = 16\n",
    "conv_pad = 2\n",
    "depth = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "388"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final = base\n",
    "for i in range(depth):\n",
    "    final = final*2\n",
    "    for u in range(2):\n",
    "        final = final - conv_pad\n",
    "    \n",
    "final\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "764"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final = base\n",
    "for u in range(2):\n",
    "    final = final + conv_pad\n",
    "for i in range(depth):\n",
    "    final = final*2\n",
    "    for u in range(2):\n",
    "        final = final + conv_pad\n",
    "    \n",
    "final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "import time\n",
    "import datetime\n",
    "# init time\n",
    "start = time.time()\n",
    "last_best_f1_test = 0\n",
    "# net network to train mode\n",
    "net.train()\n",
    "for epoch in range(startAt,epochSize):  # loop over the dataset multiple times\n",
    "\n",
    "    train_running_loss = 0.0\n",
    "    test_running_loss = 0.0\n",
    "    \n",
    "    train_running_f1 = 0.0\n",
    "    test_running_f1 = 0.0\n",
    "    \n",
    "    \n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        \n",
    "        # every start of the loop we print the percentage of completion\n",
    "        if i%1000 == 0:\n",
    "            print('%d' % int((1000 * (i+epoch*trainDataSize)/(trainDataSize*epochSize))) + 'â€° done')\n",
    "    \n",
    "        # get the inputs\n",
    "        inputs, trueImage = data\n",
    "        inputs = transforms.Lambda(lambda x : x + torch.randn_like(x)/100)(inputs)\n",
    "        # send to GPU (it already is but just to make sure)\n",
    "        if torch.cuda.is_available():\n",
    "            inputs = inputs.cuda()\n",
    "            trueImage = trueImage.cuda()\n",
    "        \n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        \n",
    "        # forward \n",
    "        outputs = net(inputs)\n",
    "        \n",
    "        # backward\n",
    "\n",
    "        loss = criterion(outputs, trueImage)\n",
    "        loss.backward()\n",
    "\n",
    "        # optimize\n",
    "        optimizer.step()\n",
    "        \n",
    "        # save statistics (set network to eval mode disables batchnormalization and dropout)\n",
    "        net.eval()\n",
    "        # make sure we don't save the gradients when getting stats so we don't train twice per image\n",
    "        with torch.no_grad():\n",
    "          # save train loss\n",
    "          train_running_loss += loss.item()\n",
    "          # save train f1\n",
    "          train_running_f1 += f1(trueImage.bool(), outputs.clone() > threshold).item()\n",
    "        net.train()\n",
    "   \n",
    "    # epoch done thus we test he model on validation set\n",
    "\n",
    "    # save statistics (set network to eval mode disables batchnormalization and dropout)\n",
    "    net.eval()\n",
    "    # make sure we don't save the gradients when getting stats so we don't train on validation set\n",
    "    with torch.no_grad():\n",
    "      for i, data in enumerate(testloader, 0):\n",
    "          \n",
    "          # get the inputs\n",
    "          inputs, trueImage = data\n",
    "          \n",
    "          # cuda them\n",
    "          if torch.cuda.is_available():\n",
    "              inputs = inputs.cuda()\n",
    "              trueImage = trueImage.cuda()\n",
    "\n",
    "          # forward and test\n",
    "\n",
    "          outputs = net(inputs)\n",
    "          loss = criterion(outputs, trueImage)\n",
    "          \n",
    "          # save statistics\n",
    "          test_running_loss += loss.item()\n",
    "          test_running_f1 += f1(trueImage.bool(), outputs.clone() > threshold).item()\n",
    "    net.train()\n",
    "    \n",
    "    # store statistics\n",
    "    trainingLoss.append(train_running_loss/trainDataSize)\n",
    "    validationLoss.append(test_running_loss/testDataSize)\n",
    "    \n",
    "    contender_f1_train = train_running_f1/trainDataSize\n",
    "    contender_f1_test = test_running_f1/testDataSize\n",
    "\n",
    "    training_f1.append(contender_f1_train)\n",
    "    validation_f1.append(contender_f1_test)\n",
    "\n",
    "    # check if the model is worth keeping\n",
    "    last_best_f1_test = save_if_best_model(net, last_best_f1_test, contender_f1_test, contender_f1_train, path_to_models, 0.2,0.2)\n",
    "    \n",
    "    # print progress so we can understand how the model is training in real time\n",
    "\n",
    "  \n",
    "    print(\"Current training loss is \" + str(train_running_loss/trainDataSize))\n",
    "    print(\"Current test loss is \" + str(test_running_loss/testDataSize))\n",
    "    print(\"Current f1_score for training is \" + str(train_running_f1/trainDataSize))\n",
    "    print(\"Current f1_score for test is \" + str(test_running_f1/testDataSize))\n",
    "    plt.plot(trainingLoss[:], label='Training loss')\n",
    "    plt.plot(validationLoss[:], label='Validation loss')\n",
    "    plt.legend(frameon=False)\n",
    "    plt.show()\n",
    "    plt.plot(training_f1[:], label='Training F1_score')\n",
    "    plt.plot(validation_f1[:], label='Validation F1_score')\n",
    "    plt.legend(frameon=False)\n",
    "    plt.show()\n",
    "\n",
    "    # after showing the progress we consider that the epochs have passed so we reset timer\n",
    "    print(\"Epoch \" + str(epoch))\n",
    "    end = time.time()\n",
    "    epochDuration = (end - start)\n",
    "    \n",
    "    # find how long we have to continue traing for\n",
    "    time_left = int((epochDuration * (epochSize-epoch+startAt-1)))\n",
    "    print(time_left)\n",
    "    durations.append(epochDuration)\n",
    "    print(\"Duration of 10 Epoch is \" + str(int(np.mean(durations)) ) + \" seconds\")\n",
    "    print(\"Estimated \" + str(str(datetime.timedelta(seconds=time_left)) ) + \" left until completion\" )\n",
    "    print()\n",
    "    start = end\n",
    "    \n",
    "print()\n",
    "print('Finished Training')\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_f1_and_loss_on_validation(testloader, threshold)\n",
    "    net.eval()\n",
    "    # make sure we don't save the gradients when getting stats so we don't train on validation set\n",
    "    with torch.no_grad():\n",
    "    for i, data in enumerate(testloader, 0):\n",
    "\n",
    "      # get the inputs\n",
    "      inputs, trueImage = data\n",
    "\n",
    "      # cuda them\n",
    "      if torch.cuda.is_available():\n",
    "          inputs = inputs.cuda()\n",
    "          trueImage = trueImage.cuda()\n",
    "\n",
    "      # forward and test\n",
    "\n",
    "      outputs = net(inputs)\n",
    "      loss = criterion(outputs, trueImage)\n",
    "\n",
    "      # save statistics\n",
    "      validation_running_loss += loss.item()\n",
    "      validation_running_f1 += f1(trueImage.bool(), outputs.clone() > threshold).item()\n",
    "        \n",
    "    size_validation = len(testloader)\n",
    "    return validation_running_loss/size_validation , validation_running_f1/size_validation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
