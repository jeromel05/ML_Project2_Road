{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import glob\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "h5_path = 'Datasets/training/images_90_ratio.h5'\n",
    "groundtruth_images_path = 'Datasets/training/groundtruth'\n",
    "satelite_images_path = 'Datasets/training/images'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "satelite_images = list(map(Image.open, glob.glob(satelite_images_path + '/*.png')))\n",
    "groundtruth_images = list(map(Image.open, glob.glob(groundtruth_images_path + '/*.png')))\n",
    "\n",
    "train_test_ratio = 0.8\n",
    "\n",
    "train_images = satelite_images[0:int(train_test_ratio*len(satelite_images))]\n",
    "train_groundtruth = groundtruth_images[0:int(train_test_ratio*len(groundtruth_images))]\n",
    "\n",
    "test_images = satelite_images[int(train_test_ratio*len(satelite_images)):]\n",
    "test_groundtruth = groundtruth_images[int(train_test_ratio*len(groundtruth_images)):]\n",
    "\n",
    "train_shape = (len(train_images), 400, 400, 3)\n",
    "train_groundtruth_shape = (len(train_images),400, 400)\n",
    "\n",
    "test_shape = (len(test_images), 400, 400, 3)\n",
    "test_groundtruth_shape = (len(test_images),400, 400)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_to_h5(h5file, name_of_group, group, convertion):\n",
    "    \n",
    "    for i in range(len(group)):\n",
    "        \n",
    "        img = group[i]\n",
    "        img = img.convert(convertion)\n",
    "        \n",
    "        img = np.array(img)\n",
    "        \n",
    "        if convertion == 'L':\n",
    "            \n",
    "            img = img > 10\n",
    "            img = img.reshape((400,400,1))\n",
    "        \n",
    "        img = np.moveaxis(img, 2, 0) # to tensor\n",
    "\n",
    "        h5file[name_of_group][i, ...] = img[None]\n",
    "        \n",
    "def add_to_h5_not_tensor(h5file, name_of_group, group, convertion):\n",
    "    \n",
    "    for i in range(len(group)):\n",
    "        \n",
    "        img = group[i]\n",
    "        \n",
    "        img = img.convert(convertion)\n",
    "        \n",
    "        img = np.array(img)\n",
    "\n",
    "        if convertion == 'L':\n",
    "            \n",
    "            img = img > 10\n",
    "            img = img*255\n",
    "#             img = img.reshape((400,400,1))\n",
    "\n",
    "        h5file[name_of_group][i, ...] = img[None]\n",
    "        \n",
    "def add_to_h5_normalized(h5file, name_of_group, group, convertion):\n",
    "    \n",
    "    for i in range(len(group)):\n",
    "        \n",
    "        img = group[i]\n",
    "        img = img.convert(convertion)\n",
    "        \n",
    "        img = np.array(img)\n",
    "        \n",
    "        if convertion == 'L':\n",
    "            \n",
    "            img = img > 10\n",
    "            img = img.reshape((400,400,1))\n",
    "        else:\n",
    "            # normalize\n",
    "            img = (img - np.mean(img))/np.std(img)\n",
    "        \n",
    "        img = np.moveaxis(img, 2, 0) # to tensor\n",
    "        h5file[name_of_group][i, ...] = img[None]\n",
    "        \n",
    "def add_to_h5_normalized_per_pixel(h5file, name_of_group, group, convertion):\n",
    "    \n",
    "    for i in range(len(group)):\n",
    "        \n",
    "        img = group[i]\n",
    "        img = img.convert(convertion)\n",
    "        \n",
    "        img = np.array(img)\n",
    "        \n",
    "        if convertion == 'L':\n",
    "            \n",
    "            img = img > 10\n",
    "            img = img.reshape((400,400,1))\n",
    "        else:\n",
    "            # normalize\n",
    "            mean = h5file[name_of_group + '_mean'][...]\n",
    "            std = h5file[name_of_group + '_std'][...]\n",
    "            img = (img - mean)/std\n",
    "            \n",
    "        \n",
    "        img = np.moveaxis(img, 2, 0) # to tensor\n",
    "        h5file[name_of_group][i, ...] = img[None]\n",
    "        \n",
    "def find_mean_and_std(h5file, means, stds, name_of_group, group):\n",
    "    # find mean\n",
    "    mean = np.zeros_like(np.array(group[0].convert('RGB'))).astype(np.float64)\n",
    "    print()\n",
    "    for i in range(len(group)):\n",
    "        \n",
    "        img = group[i]\n",
    "        img = img.convert('RGB')\n",
    "        \n",
    "        img = np.array(img)\n",
    "        \n",
    "        mean = mean + img\n",
    "        \n",
    "    mean = mean/len(group)\n",
    "    \n",
    "    h5file[means][...] = mean[None]\n",
    "    \n",
    "     # find mean\n",
    "    std = np.zeros_like(np.array(group[0].convert('RGB'))).astype(np.float64)\n",
    "    \n",
    "    for i in range(len(group)):\n",
    "        \n",
    "        img = group[i]\n",
    "        img = img.convert('RGB')\n",
    "        \n",
    "        img = np.array(img)\n",
    "        \n",
    "        std = std + (img - mean)**2\n",
    "        \n",
    "    \n",
    "    std = np.sqrt(std/(len(group) - 1))\n",
    "    h5file[stds][...] = std[None]\n",
    "    \n",
    "def online_mean_and_sd(loader):\n",
    "    \"\"\"Compute the mean and sd in an online fashion\n",
    "\n",
    "        Var[x] = E[X^2] - E^2[X]\n",
    "    \"\"\"\n",
    "    cnt = 0\n",
    "    fst_moment = torch.empty(3)\n",
    "    snd_moment = torch.empty(3)\n",
    "\n",
    "    for data in loader:\n",
    "\n",
    "        b, c, h, w = data.shape\n",
    "        nb_pixels = b * h * w\n",
    "        sum_ = torch.sum(data, dim=[0, 2, 3])\n",
    "        sum_of_square = torch.sum(data ** 2, dim=[0, 2, 3])\n",
    "        fst_moment = (cnt * fst_moment + sum_) / (cnt + nb_pixels)\n",
    "        snd_moment = (cnt * snd_moment + sum_of_square) / (cnt + nb_pixels)\n",
    "\n",
    "        cnt += nb_pixels\n",
    "\n",
    "    return fst_moment, torch.sqrt(snd_moment - fst_moment ** 2)\n",
    "    \n",
    "def find_mean_and_std_unique(h5file, means, stds, name_of_group, group):  #taken and adapted from https://discuss.pytorch.org/t/about-normalization-using-pre-trained-vgg16-networks/23560/9\n",
    "    # find mean\n",
    "    cnt = 0\n",
    "    fst_moment = np.empty(3)\n",
    "    snd_moment = np.empty(3)\n",
    "    \n",
    "    for i in range(len(group)):\n",
    "        \n",
    "        img = group[i]\n",
    "        \n",
    "        img = img.convert('RGB')\n",
    "        \n",
    "        img = np.array(img)\n",
    "        img = np.moveaxis(img, 2, 0).astype(np.float64)\n",
    "        c, h, w = img.shape\n",
    "        nb_pixels = h * w       \n",
    "        sum_ = np.sum(img, axis=(1,2))\n",
    "        sum_of_square = np.sum(img ** 2, axis=(1,2))\n",
    "        fst_moment = (cnt * fst_moment + sum_) / (cnt + nb_pixels)\n",
    "        snd_moment = (cnt * snd_moment + sum_of_square) / (cnt + nb_pixels)\n",
    "        cnt += nb_pixels\n",
    "    h5file[means][...] = fst_moment[None]  \n",
    "    h5file[stds][...] = np.sqrt(snd_moment - fst_moment ** 2)[None]  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "with h5py.File(h5_path, mode='w') as h5file:\n",
    "    \n",
    "    h5file.create_dataset(\"train\", train_shape, np.uint8)\n",
    "    h5file.create_dataset(\"train_groundtruth\", train_groundtruth_shape, np.uint8)\n",
    "    h5file.create_dataset(\"test\", test_shape, np.uint8)\n",
    "    h5file.create_dataset(\"test_groundtruth\", test_groundtruth_shape, np.uint8)\n",
    "    # for per pixel mean + std\n",
    "    h5file.create_dataset('train_mean', (1, 3), np.float64)\n",
    "    h5file.create_dataset('train_std',(1, 3), np.float64)\n",
    "    h5file.create_dataset('test_mean', (1, 3), np.float64)\n",
    "    h5file.create_dataset('test_std', (1, 3), np.float64)\n",
    "    \n",
    "\n",
    "    \n",
    "    find_mean_and_std_unique(h5file, 'train_mean', 'train_std', 'train', train_images)\n",
    "    find_mean_and_std_unique(h5file, 'test_mean', 'test_std', 'test', test_images)\n",
    "    \n",
    "    add_to_h5_not_tensor(h5file, 'train', train_images, 'RGB')\n",
    "    add_to_h5_not_tensor(h5file, 'train_groundtruth', train_groundtruth, 'L')\n",
    "    add_to_h5_not_tensor(h5file, 'test', test_images, 'RGB')\n",
    "    add_to_h5_not_tensor(h5file, 'test_groundtruth', test_groundtruth, 'L')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[84.84693063 83.85345148 74.79218188]]\n",
      "[[48.77804744 47.22947293 47.31974807]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZAAAAGQCAAAAACl1GkQAAAFOUlEQVR4nO3dwXKcOAAAUXsr///L3muczZphENAS753sSzKlRhiEsD8/Dvn67evPY//U4f//L27/SPs/wD/DPghDCBIjSIwgMYLEDAyyccXDS8yQGEFiBImZPMgdt+LnmjzIegSJESRGkBhBYgSJESRGkBhBYtYOMuEC9NpBJiTIaAeX1wSJESRGkBhBYg4GWe8B0d3MkBhBYgSJESRGkFPtX0wTJEaQGEFiRgaZ8OlDjxkSI0iMIDGCxAgSI0iMIDGCxMweZLlHlrMHWW51YPYgyxEkRpAYQWIEiREkRpAYQWIEiZk9yMbSyXw38rMHWY4gMYLECBIjSIwgMYLECDLcsafKgsQcDbLcJoO7DZ0h8y1U9DhlxQgSI0iMIDGCxAgSI0iMIOfafWsmSIwgMYLECBIjSIwgMYLECBIjSIwgMYLECBIjSIwgMYLETB9ktZ160wdZjSAxgsQIEiNIzOEgq13lDHBoSMyQGEFiBIkRJGb1INO9Zbd6kOkIEiNIjCAxY4NM9yP0fHuHxAyJESRGkBhBYgSJESRGkBhBYgSJESRGkBhBYgSJESRGkBhBYgSJESRm/iCL7fY+HmSxAbnb/DNkMYLECHKCI2dxQWIEiREkRpAYQWIEiRkcpLf9vfeJfmaGxAgSI8jZdp4zBYkRJEaQGEFiBIkRJEaQGEFiBIkRJEaQGEFiBIkRJEaQGEFiBIkRJEaQGEFiBIkRJEaQGEFiBIkRJEaQGEFiBIkRJGZAkG+vyc/2wlLOAjNk4/cm3HGIHPhVDgsEqdt3RAhyun3TRZAYQWIEiREkRpAYQWIEOZ37kBj3ITFmyNQEiREk5tfdH4DffAlyua0f8YKc4OvHb38myAuufOj4jCATPemfN8jLgzxRjY9kkLkGcLSTgzx7cN9x6C9IGe7xNoMY9Gt9GvAWa1kxgsQIEiNIjCAxgsQIEiNIjCAxgsQIEiNIjCAxgsQIEiNIjCAxgsQIEiNITHCj3FP8fcOPIBfYs/lNkF1eHtq3d1cJ8nFw++ZgTwhSGu9NUwTZGtGVdl/eGWSqI/cq44MY5kP2BPnfoV7plHG3P4M4vm/2S4EWa1kxgsQIEiNIjCAxgsQIEiNIjCAxQ4K42/+Pt4fEDIkRJEaQGEFilgiy0kXFEkFWIkiMIDGCxAhygT27csYHsSfoEDMkRpAYQWIEiXlCkKkuM54QZCqCxAgSI0iMIDGCxAgSI0iMIDGCxAgSI0iMIDGCxAgSI0iMIDGCxAgSI0iMIDGCxAgSI0iMIDGCxAhyhR2bWccE+fZe8lRbaU/z7qvaZkiMIDGCxAgSI0iMIDFrBNm4xpzpQnyNIAsRJEaQK+y4bRfkCpevZTGMIDGCxAgSI0iMIDGCxAgSI0iMIDGCxAgSI0iMIDGCxAgSI0iMIDGCxAgSI0iMIDGDgqz0px3vZYac5c1jVJAYQWIEiREkRpAYQWKeEWSid9oWCbJx0T/RfesZQSY6HnsWmSHrEOQSr580BIkRJEaQGEFinhFkogvxZwR5+I1hjxnCuwSJESRGkBhBYgSJESRGkBhBYgSJESRGkBhBYkYFmWiBu80MiREkRpDTvHcWFyRGkBhBYgSJESRGkBhBYk4JcsO+tGWWbsyQGEFiBLnGy2dxQWIEiREkRpAYQWIEiXlIkHneaXtIkHkIEiNIjCAxgsQIEiNIjCAxgsQIEiNIjCAxgsQIEiNIjCAxgsQIEiNIjCAxgsQIEjMsyLc3ZubZdZNjhsQsE2SVd9qWCbLKWXKZIKsQ5DxvXecIEvMvsdk7PQW3QPQAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=400x400 at 0x23CD9D75A90>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with h5py.File(h5_path, mode='r') as h5file:\n",
    "\n",
    "    train = h5file['train'][0,...]\n",
    "    groundtruth = h5file['train_groundtruth'][0,...]\n",
    "    mean = h5file['train_mean'][...]\n",
    "    std = h5file['train_std'][...]\n",
    "print(mean)\n",
    "print(std)\n",
    "train = train*std+mean\n",
    "train = (train).astype(\"uint8\")\n",
    "groundtruth = (groundtruth).astype(\"uint8\")\n",
    "\n",
    "groundtruth = groundtruth.reshape((400,400))\n",
    "\n",
    "train = Image.fromarray(train)\n",
    "groundtruth = Image.fromarray(groundtruth)\n",
    "\n",
    "groundtruth\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get percentage of positives compared to negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2093884375"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "size_positives = 0\n",
    "size_total = 0\n",
    "for i in range(len(groundtruth_images)):\n",
    "    \n",
    "    img = groundtruth_images[i]\n",
    " \n",
    "    img = img.convert('L')\n",
    "    img = np.array(img)\n",
    "    img = img > 10\n",
    "    \n",
    "    size_positives = size_positives + img.sum()\n",
    "    size_total = size_total + img.shape[0]*img.shape[1]\n",
    "        \n",
    "size_positives/size_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
