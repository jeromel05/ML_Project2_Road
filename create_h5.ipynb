{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import glob\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "h5_path = 'training/dataNorm.h5'\n",
    "groundtruth_images_path = 'training/groundtruth'\n",
    "satelite_images_path = 'training/images'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "satelite_images = list(map(Image.open, glob.glob(satelite_images_path + '/*.png')))\n",
    "groundtruth_images = list(map(Image.open, glob.glob(groundtruth_images_path + '/*.png')))\n",
    "\n",
    "train_test_ratio = 0.6\n",
    "\n",
    "train_images = satelite_images[0:int(train_test_ratio*len(satelite_images))]\n",
    "train_groundtruth = groundtruth_images[0:int(train_test_ratio*len(groundtruth_images))]\n",
    "\n",
    "test_images = satelite_images[int(train_test_ratio*len(satelite_images)):]\n",
    "test_groundtruth = groundtruth_images[int(train_test_ratio*len(groundtruth_images)):]\n",
    "\n",
    "train_shape = (len(train_images), 3, 400, 400)\n",
    "train_groundtruth_shape = (len(train_images), 1, 400, 400)\n",
    "\n",
    "test_shape = (len(test_images), 3, 400, 400)\n",
    "test_groundtruth_shape = (len(test_images), 1, 400, 400)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_to_h5(h5file, name_of_group, group, convertion):\n",
    "    \n",
    "    for i in range(len(group)):\n",
    "        \n",
    "        img = group[i]\n",
    "        img = img.convert(convertion)\n",
    "        \n",
    "        img = np.array(img)\n",
    "        \n",
    "        if convertion == 'L':\n",
    "            \n",
    "            img = img > 10\n",
    "            img = img.reshape((400,400,1))\n",
    "        \n",
    "        img = np.moveaxis(img, 2, 0) # to tensor\n",
    "        h5file[name_of_group][i, ...] = img[None]\n",
    "        \n",
    "def add_to_h5_normalized(h5file, name_of_group, group, convertion):\n",
    "    \n",
    "    for i in range(len(group)):\n",
    "        \n",
    "        img = group[i]\n",
    "        img = img.convert(convertion)\n",
    "        \n",
    "        img = np.array(img)\n",
    "        \n",
    "        if convertion == 'L':\n",
    "            \n",
    "            img = img > 10\n",
    "            img = img.reshape((400,400,1))\n",
    "        else:\n",
    "            # normalize\n",
    "            img = (img - np.mean(img))/np.std(img)\n",
    "        \n",
    "        img = np.moveaxis(img, 2, 0) # to tensor\n",
    "        h5file[name_of_group][i, ...] = img[None]\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "with h5py.File(h5_path, mode='w') as h5file:\n",
    "    \n",
    "    h5file.create_dataset(\"train\", train_shape, np.float64)\n",
    "    h5file.create_dataset(\"train_groundtruth\", train_groundtruth_shape, np.bool)\n",
    "    h5file.create_dataset(\"test\", test_shape, np.float64)\n",
    "    h5file.create_dataset(\"test_groundtruth\", test_groundtruth_shape, np.bool)\n",
    "    \n",
    "    add_to_h5(h5file, 'train', train_images, 'RGB')\n",
    "    add_to_h5(h5file, 'train_groundtruth', train_groundtruth, 'L')\n",
    "    add_to_h5(h5file, 'test', test_images, 'RGB')\n",
    "    add_to_h5(h5file, 'test_groundtruth', test_groundtruth, 'L')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZAAAAGQCAAAAACl1GkQAAAFOUlEQVR4nO3dwXKcOAAAUXsr///L3muczZphENAS753sSzKlRhiEsD8/Dvn67evPY//U4f//L27/SPs/wD/DPghDCBIjSIwgMYLEDAyyccXDS8yQGEFiBImZPMgdt+LnmjzIegSJESRGkBhBYgSJESRGkBhBYtYOMuEC9NpBJiTIaAeX1wSJESRGkBhBYg4GWe8B0d3MkBhBYgSJESRGkFPtX0wTJEaQGEFiRgaZ8OlDjxkSI0iMIDGCxAgSI0iMIDGCxMweZLlHlrMHWW51YPYgyxEkRpAYQWIEiREkRpAYQWIEiZk9yMbSyXw38rMHWY4gMYLECBIjSIwgMYLECDLcsafKgsQcDbLcJoO7DZ0h8y1U9DhlxQgSI0iMIDGCxAgSI0iMIOfafWsmSIwgMYLECBIjSIwgMYLECBIjSIwgMYLECBIjSIwgMYLETB9ktZ160wdZjSAxgsQIEiNIzOEgq13lDHBoSMyQGEFiBIkRJGb1INO9Zbd6kOkIEiNIjCAxY4NM9yP0fHuHxAyJESRGkBhBYgSJESRGkBhBYgSJESRGkBhBYgSJESRGkBhBYgSJESRm/iCL7fY+HmSxAbnb/DNkMYLECHKCI2dxQWIEiREkRpAYQWIEiRkcpLf9vfeJfmaGxAgSI8jZdp4zBYkRJEaQGEFiBIkRJEaQGEFiBIkRJEaQGEFiBIkRJEaQGEFiBIkRJEaQGEFiBIkRJEaQGEFiBIkRJEaQGEFiBIkRJGZAkG+vyc/2wlLOAjNk4/cm3HGIHPhVDgsEqdt3RAhyun3TRZAYQWIEiREkRpAYQWIEOZ37kBj3ITFmyNQEiREk5tfdH4DffAlyua0f8YKc4OvHb38myAuufOj4jCATPemfN8jLgzxRjY9kkLkGcLSTgzx7cN9x6C9IGe7xNoMY9Gt9GvAWa1kxgsQIEiNIjCAxgsQIEiNIjCAxgsQIEiNIjCAxgsQIEiNIjCAxgsQIEiNITHCj3FP8fcOPIBfYs/lNkF1eHtq3d1cJ8nFw++ZgTwhSGu9NUwTZGtGVdl/eGWSqI/cq44MY5kP2BPnfoV7plHG3P4M4vm/2S4EWa1kxgsQIEiNIjCAxgsQIEiNIjCAxQ4K42/+Pt4fEDIkRJEaQGEFilgiy0kXFEkFWIkiMIDGCxAhygT27csYHsSfoEDMkRpAYQWIEiXlCkKkuM54QZCqCxAgSI0iMIDGCxAgSI0iMIDGCxAgSI0iMIDGCxAgSI0iMIDGCxAgSI0iMIDGCxAgSI0iMIDGCxAhyhR2bWccE+fZe8lRbaU/z7qvaZkiMIDGCxAgSI0iMIDFrBNm4xpzpQnyNIAsRJEaQK+y4bRfkCpevZTGMIDGCxAgSI0iMIDGCxAgSI0iMIDGCxAgSI0iMIDGCxAgSI0iMIDGCxAgSI0iMIDGDgqz0px3vZYac5c1jVJAYQWIEiREkRpAYQWKeEWSid9oWCbJx0T/RfesZQSY6HnsWmSHrEOQSr580BIkRJEaQGEFinhFkogvxZwR5+I1hjxnCuwSJESRGkBhBYgSJESRGkBhBYgSJESRGkBhBYkYFmWiBu80MiREkRpDTvHcWFyRGkBhBYgSJESRGkBhBYk4JcsO+tGWWbsyQGEFiBLnGy2dxQWIEiREkRpAYQWIEiXlIkHneaXtIkHkIEiNIjCAxgsQIEiNIjCAxgsQIEiNIjCAxgsQIEiNIjCAxgsQIEiNIjCAxgsQIEjMsyLc3ZubZdZNjhsQsE2SVd9qWCbLKWXKZIKsQ5DxvXecIEvMvsdk7PQW3QPQAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=400x400 at 0x1A2433AFA20>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with h5py.File(h5_path, mode='r') as h5file:\n",
    "\n",
    "    train = h5file['train'][0,...]\n",
    "    groudtruth = h5file['train_groundtruth'][0,...]\n",
    "    \n",
    "train = np.moveaxis(train, 0, 2)\n",
    "groundtruth = np.moveaxis(groudtruth, 0, 2)\n",
    "\n",
    "train = train.astype(\"uint8\")\n",
    "groundtruth = groundtruth.astype(\"uint8\")\n",
    "\n",
    "groundtruth = groundtruth.reshape((400,400))\n",
    "\n",
    "train = Image.fromarray(train)\n",
    "groudtruth = Image.fromarray(groundtruth*255)\n",
    "\n",
    "\n",
    "groudtruth\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get percentage of positives compared to negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2093884375"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "size_positives = 0\n",
    "size_total = 0\n",
    "for i in range(len(groundtruth_images)):\n",
    "    \n",
    "    img = groundtruth_images[i]\n",
    " \n",
    "    img = img.convert('L')\n",
    "    img = np.array(img)\n",
    "    img = img > 10\n",
    "    \n",
    "    size_positives = size_positives + img.sum()\n",
    "    size_total = size_total + img.shape[0]*img.shape[1]\n",
    "        \n",
    "size_positives/size_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
