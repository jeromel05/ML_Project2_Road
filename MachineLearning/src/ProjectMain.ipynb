{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import cv2\n",
    "import os,sys\n",
    "import pickle\n",
    "import scipy.stats\n",
    "import sklearn.metrics\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.cm as cm # To colour dots of scatter plots\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from skimage.feature import hog\n",
    "from scipy.stats import norm\n",
    "from sklearn import preprocessing\n",
    "from itertools import combinations\n",
    "from PIL import Image\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1, './utilities/')\n",
    "\n",
    "from utility_functions import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loaded a set of images\n",
    "root_dir = \"../../Datasets/training/\"\n",
    "\n",
    "image_dir = root_dir + \"images/\"\n",
    "files = os.listdir(image_dir)\n",
    "n = min(20, len(files)) # Load maximum 20 images\n",
    "print(\"Loading \" + str(n) + \" images\")\n",
    "imgs = [load_image(image_dir + files[i]) for i in range(n)]\n",
    "print(files[0])\n",
    "\n",
    "gt_dir = root_dir + \"groundtruth/\"\n",
    "print(\"Loading \" + str(n) + \" images\")\n",
    "gt_imgs = [load_image(gt_dir + files[i]) for i in range(n)]\n",
    "print(files[0])\n",
    "\n",
    "n = 10 # Only use 10 images for training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split the images into smaller patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract patches from input images\n",
    "# size = 10(nb_images)*625(n_patches_per_image)*16*16(size_patch)*3(nb_channels)\n",
    "patch_size = 16  # each patch is 16*16 pixels\n",
    "\n",
    "img_patches = [img_crop(imgs[i], patch_size, patch_size) for i in range(n)]\n",
    "gt_patches = [img_crop(gt_imgs[i], patch_size, patch_size) for i in range(n)]\n",
    "\n",
    "# Linearize list of patches\n",
    "img_patches = np.asarray([img_patches[i][j] for i in range(len(img_patches)) for j in range(len(img_patches[i]))])\n",
    "gt_patches =  np.asarray([gt_patches[i][j] for i in range(len(gt_patches)) for j in range(len(gt_patches[i]))])\n",
    "#return array of size 6250 containing all the 625 patches for all the 10 training images\n",
    "#gt has only 0 or 1 values\n",
    "#img has an rgb value of size 3 for each point"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extraction of Features from the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: More features + feature interaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#line detection\n",
    "#TODO: transformer ca en feature\n",
    "def proba_hough_tranform(img):\n",
    "    img = img_float_to_uint8(img)\n",
    "    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    #edges = cv2.Canny(gray,50,150,apertureSize = 3)\n",
    "    edges = ndimage.gaussian_laplace(gray, sigma=2.5)\n",
    "    features = np.zeros_like(2*img.shape[0])\n",
    "    \n",
    "    #plt.imshow(edges)\n",
    "    #plt.show()\n",
    "    minLineLength = 100\n",
    "    maxLineGap = 120\n",
    "    lines = cv2.HoughLinesP(edges,0.01,np.pi/360,100,minLineLength,maxLineGap)\n",
    "    for i in range(len(lines)):\n",
    "        for x1,y1,x2,y2 in lines[i]:\n",
    "            cv2.line(img,(x1,y1),(x2,y2),(0,255,0),2)\n",
    "            \n",
    "    #cv2.imwrite('houghlines5.jpg',img)\n",
    "    plt.imshow(img)\n",
    "    plt.show()\n",
    "    \n",
    "    return features\n",
    "   \n",
    "proba_hough_tranform(imgs[3])\n",
    "plt.imshow(gt_imgs[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#important feature detection (corners)\n",
    "from skimage.feature import corner_harris, corner_subpix, corner_peaks, CENSURE\n",
    "from skimage.color import rgb2gray\n",
    "\n",
    "def corner_detection(image):\n",
    "    image = image.astype('double')\n",
    "    img_orig = rgb2gray(image)\n",
    "    detector = CENSURE(min_scale=1,max_scale=3,mode='DoB',non_max_threshold=0.15,line_threshold=10)\n",
    "    detector.detect(img_orig)\n",
    "\n",
    "    coords = corner_peaks(corner_harris(img_orig), min_distance=100)\n",
    "    coords_subpix = corner_subpix(img_orig, coords, window_size=13)\n",
    "\n",
    "    plt.title('CENSURE feature detection')\n",
    "    plt.imshow(img_orig)\n",
    "    plt.scatter(detector.keypoints[:, 1], detector.keypoints[:, 0],\n",
    "            2 ** detector.scales, facecolors='none', edgecolors='r')\n",
    "    \n",
    "corner_detection(imgs[0])\n",
    "plt.imshow(gt_imgs[0])\n",
    "#rem: there are a lot of corners along roads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#example of whole pipeline\n",
    "img = rgb2gray(imgs[3])\n",
    "plt.imshow(img)\n",
    "plt.show()\n",
    "img = img_float_to_uint8(img)\n",
    "ret,thresh1 = cv2.threshold(img,127,255,cv2.THRESH_BINARY)\n",
    "kernel = np.ones((5,5),np.uint8)\n",
    "erosion = cv2.erode(thresh1,kernel,iterations = 1)\n",
    "plt.imshow(erosion)\n",
    "plt.show()\n",
    "#Removing noise from image\n",
    "blur = cv2.blur(img,(5,5))\n",
    "plt.imshow(blur)\n",
    "plt.show()\n",
    "#finding edges using edge detection\n",
    "edges = cv2.Canny(blur, 100 ,200)\n",
    "plt.imshow(edges)\n",
    "plt.show()\n",
    "\n",
    "laplacian = cv2.Laplacian(edges, cv2.CV_8UC1)\n",
    "sobely = cv2.Sobel(laplacian,cv2.CV_8UC1, 0, 1, ksize=5)\n",
    "plt.imshow(edges)\n",
    "plt.show()\n",
    "\n",
    "# Do a dilation and erosion to accentuate the triangle shape\n",
    "dilated = cv2.dilate(sobely,kernel,iterations = 1)\n",
    "#erosion = cv2.erode(dilated,kernel,iterations = 1)\n",
    "\n",
    "plt.imshow(dilated)\n",
    "plt.show()\n",
    "plt.imshow(gt_imgs[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hog_features(image):\n",
    "    #histogram of oriented gradients\n",
    "    grey_bombus = rgb2gray(image)\n",
    "    hog_features, hog_image = hog(grey_bombus,\n",
    "                              visualize=True,\n",
    "                              block_norm='L2-Hys',\n",
    "                              pixels_per_cell=(8,8))\n",
    "        \n",
    "    #plt.imshow(hog_image, cmap=cm.gray)\n",
    "    return hog_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3 new features\n",
    "import mahotas\n",
    "\n",
    "def fd_hu_moments(image):\n",
    "    image = img_float_to_uint8(image)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    feature = cv2.HuMoments(cv2.moments(image)).flatten()\n",
    "    return feature\n",
    "def fd_haralick(image):    # convert the image to grayscale\n",
    "    image = img_float_to_uint8(image)\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    # compute the haralick texture feature vector\n",
    "    haralick = mahotas.features.haralick(gray).mean(axis=0)\n",
    "    return haralick\n",
    " \n",
    "#fd hist ne marche pas encore\n",
    "def fd_histogram(image, mask=None):\n",
    "    image = img_float_to_uint8(image)\n",
    "    # convert the image to HSV color-space\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "    # compute the color histogram\n",
    "    hist  = cv2.calcHist([image], [0, 1, 2], None, [3, 3, 3], [0, 256, 0, 256, 0, 256])\n",
    "    # normalize the histogram\n",
    "    cv2.normalize(hist, hist)\n",
    "    hist.flatten()\n",
    "    \n",
    "print(fd_hu_moments(imgs[3]))\n",
    "print(fd_haralick(imgs[3]) ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Features definition\n",
    "def features_definition(img_patches):\n",
    "    print(\"compute X1\")\n",
    "    X1 = np.asarray([ extract_features(img_patches[i]) for i in range(len(img_patches))]) # dim 6\n",
    "    print(\"Added dims: \" + str(X1.shape[1]))\n",
    "    X2 = np.asarray([ laplace_gaussian_edge_detection(img_patches[i]) for i in range(len(img_patches))]) # dim 102\n",
    "    print(\"Added dims: \" + str(X2.shape[1]))\n",
    "    X3 = np.asarray([ horizontal_and_vertical_edge_detection(img_patches[i]) for i in range(len(img_patches))]) # dim 6\n",
    "    print(\"Added dims: \" + str(X3.shape[1]))\n",
    "    X4 = np.asarray([ get_grey_features(get_gray_mask(img_patches[i])) for i in range(len(img_patches))]) # dim 32\n",
    "    #X4 = np.asarray([ get_gray_mask(img_patches[i]).ravel() for i in range(len(img_patches))]) # dim 16 * 16\n",
    "    print(\"Added dims: \" + str(X4.shape[1]))\n",
    "    #X5 = np.asarray([ to_grayscale(img_patches[i]).ravel() for i in range(len(img_patches))]) # dim 16 * 16\n",
    "    #print(\"Added dims: \" + str(X5.shape[1]))\n",
    "    X6 = np.asarray([ fd_hu_moments(img_patches[i]) for i in range(len(img_patches))]) # dim 7\n",
    "    print(\"Added dims: \" + str(X6.shape[1]))\n",
    "    X7 = np.asarray([ fd_haralick(img_patches[i]) for i in range(len(img_patches))]) # dim 13\n",
    "    print(\"Added dims: \" + str(X7.shape[1]))\n",
    "    X8 = np.asarray([ hog_features(img_patches[i]).ravel() for i in range(len(img_patches))]) # dim 16 * 16\n",
    "    print(\"Added dims: \" + str(X8.shape[1]))\n",
    "    print(\"stop\")\n",
    "    X = np.concatenate((X1,X2,X3,X4,X6,X7,X8),axis=1) # dim 402\n",
    "    #X = feature_expansion(X,4) # dim = dim * degree\n",
    "    X = add_offset(X) # dim = dim + 1\n",
    "    print(X.shape)\n",
    "\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = features_definition(img_patches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalization\n",
    "scaler = preprocessing.MinMaxScaler()\n",
    "scaler.fit(X)\n",
    "X_scaled = scaler.transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definition of the output y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Definition of two classes for the patches\n",
    "\n",
    "# Compute features for each image patch\n",
    "foreground_threshold = 0.25 # percentage of pixels > 1 required to assign a foreground label to a patch\n",
    "\n",
    "def value_to_class(v):\n",
    "    df = np.sum(v)\n",
    "    if df > foreground_threshold:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "#the class foreground has a bit of road in it (25% min)\n",
    "Y = np.asarray([value_to_class(np.mean(gt_patches[i])) for i in range(len(gt_patches))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Statistics on computed features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print feature statistics\n",
    "print('Computed ' + str(X.shape[0]) + ' features')\n",
    "print('Feature dimension = ' + str(X.shape[1]))\n",
    "print('Number of classes = ' + str(np.max(Y)))  #TODO: fix, length(unique(Y)) \n",
    "\n",
    "Y0 = [i for i, j in enumerate(Y) if j == 0]\n",
    "Y1 = [i for i, j in enumerate(Y) if j == 1]\n",
    "print('Class 0: ' + str(len(Y0)) + ' samples')\n",
    "print('Class 1: ' + str(len(Y1)) + ' samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hist_of_features(X):\n",
    "    \"\"\"\n",
    "    performs a histogram of the distribution of all the parameters in the dataset \n",
    "    parameters:\n",
    "        X: the dataset to plot\n",
    "    \"\"\"\n",
    "    n = X.shape[1]\n",
    "    fig, ax = plt.subplots(4,5)\n",
    "\n",
    "    for i in range(4):\n",
    "        for j in range(5):\n",
    "            ax[i,j].hist(X[:,i+j], bins = 30)\n",
    "            ax[i,j].set_title(i+j,fontsize=40)\n",
    "        \n",
    "    fig.set_figheight(150)\n",
    "    fig.set_figwidth(150)\n",
    "    plt.suptitle(\"Distribution of all the features\",fontsize=150)\n",
    "    plt.tight_layout()\n",
    "    fig.subplots_adjust(top=0.92)\n",
    "    plt.show()\n",
    "    \n",
    "hist_of_features(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA and Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=10)\n",
    "pca.fit(X.T)  \n",
    "colors = ['c' if yi else 'm' for yi in Y]\n",
    "print(pca.explained_variance_ratio_[:10], pca.components_.shape)  \n",
    "plt.scatter(pca.components_[0],Y, s=20, c=colors)\n",
    "#first component explains 99% variance -> but still no clear separation between y1 and y0\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(np.log(pca.components_[0]),np.log(pca.components_[2]), s=10, c=colors)\n",
    "print(np.mean(pca.components_[0]), np.var(pca.components_[0]))\n",
    "print(np.where(pca.components_[1] > 0.1), pca.components_[0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define parameters\n",
    "proportion_class0 = (len(Y0)) / (len(Y))\n",
    "proportion_class1 = (len(Y1)) / (len(Y))\n",
    "print(proportion_class0,proportion_class1)\n",
    "weight = {0:proportion_class1, 1:proportion_class0}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train a logistic regression classifier\n",
    "from sklearn import linear_model\n",
    "import time\n",
    "\n",
    "# we create an instance of the classifier and fit the data\n",
    "logreg = linear_model.LogisticRegression(C=1e4,solver='liblinear',penalty='l1',class_weight=weight,verbose=3)\n",
    "# Run the estimation\n",
    "start = time.time()\n",
    "logreg.fit(pca.components_.T, Y)\n",
    "stop = time.time()\n",
    "print(stop - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on the training set\n",
    "Z = logreg.predict(pca.components_.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Best score yet: 0.230769"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#in general the SVM performs better than the LogReg model\n",
    "from sklearn import svm\n",
    "#pca.components_.T\n",
    "\n",
    "clf = svm.SVC(C=1.0, cache_size=200, class_weight=weight, coef0=0.0,\n",
    "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
    "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
    "    tol=0.001, verbose=True)\n",
    "clf.fit(X, Y)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on the training set\n",
    "Z = clf.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sum(Z),sum(Y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get non-zeros in prediction and grountruth arrays\n",
    "Zn = np.nonzero(Z)[0]\n",
    "Yn = np.nonzero(Y)[0]\n",
    "recall = len(list(set(Yn) & set(Zn))) / float(len(Z)) #Recall = TPR\n",
    "precision = len(list(set(Yn) & set(Zn))) / float(len(Y))\n",
    "F1 = 2*(recall*precision)/(recall+precision)\n",
    "print('F1 Score = ' + str(F1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Display of results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_idx = 12\n",
    "\n",
    "Xi = extract_img_features(image_dir + files[img_idx],patch_size)\n",
    "Zi = logreg.predict(Xi)\n",
    "plt.scatter(Xi[:, 1], Xi[:, 10], c=Zi, edgecolors='k', cmap=plt.cm.Paired)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = gt_imgs[img_idx].shape[0]\n",
    "h = gt_imgs[img_idx].shape[1]\n",
    "predicted_im = label_to_img(w, h, patch_size, patch_size, Zi)\n",
    "cimg = concatenate_images(imgs[img_idx], predicted_im)\n",
    "fig1 = plt.figure(figsize=(10, 10)) # create a figure with the default size \n",
    "plt.imshow(cimg, cmap='Greys_r')\n",
    "\n",
    "new_img = make_img_overlay(imgs[img_idx], predicted_im)\n",
    "\n",
    "plt.imshow(new_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
