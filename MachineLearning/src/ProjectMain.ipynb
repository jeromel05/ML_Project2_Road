{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import cv2\n",
    "import os,sys\n",
    "import pickle\n",
    "import mahotas\n",
    "import scipy.stats\n",
    "import sklearn.metrics\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.cm as cm # To color dots of scatter plots\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from skimage.feature import hog\n",
    "from scipy.stats import norm\n",
    "from sklearn import preprocessing\n",
    "from itertools import combinations\n",
    "from PIL import Image\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1, './utilities/')\n",
    "\n",
    "import utility_functions as utl\n",
    "import feature_expansion_functions as ftexp\n",
    "import helper_functions as hlp\n",
    "import plot_functions as pltf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading 20 images\n",
      "satImage_052.png\n",
      "Loading 20 images\n",
      "satImage_052.png\n"
     ]
    }
   ],
   "source": [
    "# Loaded a set of images\n",
    "root_dir = \"../../Datasets/training/\"\n",
    "\n",
    "image_dir = root_dir + \"images/\"\n",
    "files = os.listdir(image_dir)\n",
    "n = min(20, len(files)) # Load maximum 20 images\n",
    "print(\"Loading \" + str(n) + \" images\")\n",
    "imgs = [hlp.load_image(image_dir + files[i]) for i in range(n)]\n",
    "print(files[0])\n",
    "\n",
    "gt_dir = root_dir + \"groundtruth/\"\n",
    "print(\"Loading \" + str(n) + \" images\")\n",
    "gt_imgs = [hlp.load_image(gt_dir + files[i]) for i in range(n)]\n",
    "print(files[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split the images into smaller patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 10 # Only use 10 images for training\n",
    "# Extract patches from input images\n",
    "# size = 10(nb_images)*625(n_patches_per_image)*16*16(size_patch)*3(nb_channels)\n",
    "patch_size = 16  # each patch is 16*16 pixels\n",
    "\n",
    "img_patches = [hlp.img_crop(imgs[i], patch_size, patch_size) for i in range(n)]\n",
    "gt_patches = [hlp.img_crop(gt_imgs[i], patch_size, patch_size) for i in range(n)]\n",
    "\n",
    "# Linearize list of patches\n",
    "img_patches = np.asarray([img_patches[i][j] for i in range(len(img_patches)) for j in range(len(img_patches[i]))])\n",
    "gt_patches =  np.asarray([gt_patches[i][j] for i in range(len(gt_patches)) for j in range(len(gt_patches[i]))])\n",
    "#return array of size 6250 containing all the 625 patches for all the 10 training images\n",
    "#gt has only 0 or 1 values\n",
    "#img has an rgb value of size 3 for each point"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extraction of Features from the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.36089089e-03 1.31989277e-09 2.95904967e-12 7.73801105e-12\n",
      " 4.66044940e-24 9.55746477e-17 3.67326717e-23]\n",
      "[ 1.88039899e-04  9.03837665e+02  7.84923668e-01  2.10103189e+03\n",
      "  1.20263066e-01  1.40146298e+02  7.50028990e+03  8.21881821e+00\n",
      "  1.34113709e+01  1.30991713e-04  5.49662066e+00 -1.61067899e-01\n",
      "  9.45007905e-01]\n"
     ]
    }
   ],
   "source": [
    "#fd hist ne marche pas encore\n",
    "def fd_histogram(image, mask=None):\n",
    "    image = img_float_to_uint8(image)\n",
    "    # convert the image to HSV color-space\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "    # compute the color histogram\n",
    "    # documentation: cv.calcHist(images, channels, mask, histSize, ranges[, hist[, accumulate]])\n",
    "    hist  = cv2.calcHist([image], [0, 1, 2], None, [3, 3, 3], [0, 256, 0, 256, 0, 256])\n",
    "    # normalize the histogram\n",
    "    cv2.normalize(hist, hist)\n",
    "    hist.flatten()\n",
    "    \n",
    "print(utl.fd_hu_moments(imgs[3]))\n",
    "print(utl.fd_haralick(imgs[3]) ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Features definition\n",
    "def features_definition_temp(img_patches):\n",
    "    print(\"compute X1\")\n",
    "    X1 = np.asarray([ utl.extract_features(img_patches[i]) for i in range(len(img_patches))]) # dim 6\n",
    "    print(\"Added dims: \" + str(X1.shape[1]))\n",
    "    X2 = np.asarray([ utl.laplace_gaussian_edge_detection(img_patches[i]) for i in range(len(img_patches))]) # dim 32\n",
    "    print(\"Added dims: \" + str(X2.shape[1]))\n",
    "    X3 = np.asarray([ utl.horizontal_and_vertical_edge_detection(img_patches[i]) for i in range(len(img_patches))]) # dim 32\n",
    "    print(\"Added dims: \" + str(X3.shape[1]))\n",
    "    X4 = np.asarray([ utl.get_grey_features(utl.get_gray_mask(img_patches[i])) for i in range(len(img_patches))]) # dim 32\n",
    "    #X4 = np.asarray([ get_gray_mask(img_patches[i]).ravel() for i in range(len(img_patches))]) # dim 16 * 16\n",
    "    print(\"Added dims: \" + str(X4.shape[1]))\n",
    "    X5 = np.asarray([ utl.threshold_eroded_img(img_patches[i]) for i in range(len(img_patches))]) # dim 32\n",
    "    print(\"Added dims: \" + str(X5.shape[1]))\n",
    "    X6 = np.asarray([ utl.fd_hu_moments(img_patches[i]) for i in range(len(img_patches))]) # dim 7\n",
    "    print(\"Added dims: \" + str(X6.shape[1]))\n",
    "    X7 = np.asarray([ utl.fd_haralick(img_patches[i]) for i in range(len(img_patches))]) # dim 13\n",
    "    print(\"Added dims: \" + str(X7.shape[1]))\n",
    "    X8 = np.asarray([ utl.hog_features(img_patches[i]).ravel() for i in range(len(img_patches))]) # dim 16 * 16\n",
    "    print(\"Added dims: \" + str(X8.shape[1]))\n",
    "    print(\"stop\")\n",
    "    X = np.concatenate((X1,X2,X3,X4,X6,X7,X8),axis=1) # dim 402\n",
    "    #X = feature_expansion(X,4) # dim = dim * degree\n",
    "    X = ftexp.feature_interaction(X) # dim = dim**2\n",
    "    X = ftexp.add_offset(X) # dim = dim + 1\n",
    "    print(X.shape)\n",
    "\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = features_definition_temp(img_patches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r\"../saved_data/all_features.pickle\", \"wb\") as output_file:\n",
    "    pickle.dump(X, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalization\n",
    "scaler = preprocessing.MinMaxScaler()\n",
    "scaler.fit(X)\n",
    "X_scaled = scaler.transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definition of the output y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Definition of two classes for the patches\n",
    "foreground_threshold = 0.2 # percentage of pixels > 1 required to assign a foreground label to a patch\n",
    "#the class foreground has a bit of road in it (25% min)\n",
    "Y = np.asarray([hlp.value_to_class(np.mean(gt_patches[i]), foreground_threshold) for i in range(len(gt_patches))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Statistics on computed features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pltf.print_feature_stats(X_scaled,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hist_of_features(X)\n",
    "corr1 = np.corrcoef(X_scaled.T)\n",
    "f,a = plt.subplots()\n",
    "heatmap_corr = a.imshow(corr1)\n",
    "f.colorbar(heatmap_corr, ax=a)\n",
    "res = np.where(corr1 > 0.95) #arbitrary threshold for strong correlation\n",
    "listOfCoordinates= list(zip(res[0], res[1]))\n",
    "listOfCoordinates = [cord for cord in listOfCoordinates if cord[0] != cord[1]] #remove diagonal\n",
    "listOfCoordinates = {tuple(sorted(t)): t for t in listOfCoordinates}#remove commutative elements\n",
    "print(listOfCoordinates.keys())\n",
    "plt.savefig(\"../plots/correlation_matrix\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA and Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=300)\n",
    "pca.fit(X_scaled)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_reduced = pca.transform(X_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_reduced.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r\"../saved_data/all_features_pca_components.pickle\", \"wb\") as output_file:\n",
    "    pickle.dump(pca.components_, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = ['c' if yi else 'm' for yi in Y]\n",
    "print(pca.explained_variance_ratio_[:10], pca.components_.shape)  \n",
    "plt.scatter(pca.components_[0],Y, s=20, c=colors)\n",
    "#first component explains 99% variance -> but still no clear separation between y1 and y0\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(np.log(pca.components_[1]),np.log(pca.components_[3]), s=10, c=colors)\n",
    "print(np.mean(pca.components_[0]), np.var(pca.components_[0]))\n",
    "print(np.where(pca.components_[1] > 0.1), pca.components_[0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define parameters\n",
    "#pb si on a 80% de negatif... ?\n",
    "Y0 = [i for i, j in enumerate(Y) if j == 0]\n",
    "Y1 = [i for i, j in enumerate(Y) if j == 1]\n",
    "    \n",
    "proportion_class0 = (len(Y0)) / (len(Y))\n",
    "proportion_class1 = (len(Y1)) / (len(Y))\n",
    "print(proportion_class0,proportion_class1)\n",
    "weight = {0:proportion_class1, 1:proportion_class0}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train a logistic regression classifier\n",
    "from sklearn import linear_model\n",
    "import time\n",
    "\n",
    "# we create an instance of the classifier and fit the data\n",
    "logreg = linear_model.LogisticRegression(C=1e4,solver='liblinear',penalty='l1',class_weight=weight,verbose=3)\n",
    "# Run the estimation\n",
    "start = time.time()\n",
    "logreg.fit(pca.components_.T, Y)\n",
    "stop = time.time()\n",
    "print(stop - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on the training set\n",
    "Z = logreg.predict(pca.components_.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#in general the SVM performs better than the LogReg model\n",
    "from sklearn import svm\n",
    "\n",
    "clf2 = svm.SVC(C=10, cache_size=200, class_weight=weight, coef0=0.0,\n",
    "    decision_function_shape='ovr', degree=4, gamma='scale', kernel='rbf',\n",
    "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
    "    tol=0.001, verbose=True)\n",
    "clf2.fit(X_reduced, Y)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on the training set\n",
    "Z = clf.predict(X_reduced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r\"../saved_data/all_features_svm_prediction.pickle\", \"wb\") as output_file:\n",
    "    pickle.dump(Z, output_file)\n",
    "with open(r\"../saved_data/all_features_svm_model.pickle\", \"wb\") as output_file:\n",
    "    pickle.dump(clf, output_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sum(Y),sum(Z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#F1 Score\n",
    "print(f1_score(Y, Z, average='binary'), accuracy_score(Y, Z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loaded a set of images\n",
    "root_dir_test = \"../../Datasets/test_set_images/test_\"\n",
    "\n",
    "n=50\n",
    "print(\"Loading \" + str(n) + \" images\")\n",
    "test_imgs = []\n",
    "for i in range(n-1):\n",
    "    image_dir_test = root_dir_test + str(i+1) + \"/\"\n",
    "    file = os.listdir(image_dir_test)\n",
    "    #print(\"Loading \" + str(file))\n",
    "    test_imgs.append(load_image(image_dir_test + file[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Display of results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_idx = 11\n",
    "Xi = extract_img_features(image_dir + files[img_idx],patch_size)\n",
    "#normalization\n",
    "scaler = preprocessing.MinMaxScaler()\n",
    "scaler.fit(Xi)\n",
    "Xi_scaled = scaler.transform(Xi)\n",
    "\n",
    "pca1 = PCA(n_components=300)\n",
    "pca1.fit(Xi_scaled.T)  \n",
    "Zi = clf.predict(pca1.components_.T)\n",
    "plt.scatter(Xi[:, 1], Xi[:, 2], c=Zi, edgecolors='k', cmap=plt.cm.Paired)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sum(Zi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = gt_imgs[img_idx].shape[0]\n",
    "h = gt_imgs[img_idx].shape[1]\n",
    "predicted_im = label_to_img(w, h, patch_size, patch_size, Zi)\n",
    "cimg = concatenate_images(imgs[img_idx], predicted_im)\n",
    "fig1 = plt.figure(figsize=(10, 10)) # create a figure with the default size \n",
    "plt.imshow(cimg, cmap='Greys_r')\n",
    "\n",
    "new_img = make_img_overlay(imgs[img_idx], predicted_im)\n",
    "\n",
    "plt.imshow(new_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: make feature mat from test_set data and make predictions and then the csv\n",
    "#use the remaining imgs as validation set\n",
    "n = 10 # Only use 10 images for test\n",
    "patch_size = 16  # each patch is 16*16 pixels\n",
    "\n",
    "img_patches_val = [img_crop(imgs[i], patch_size, patch_size) for i in np.arange(10,20,1)]\n",
    "gt_patches_val = [img_crop(gt_imgs[i], patch_size, patch_size) for i in np.arange(10,20,1)]\n",
    "\n",
    "# Linearize list of patches\n",
    "img_patches_val = np.asarray([img_patches_val[i][j] for i in range(len(img_patches_val)) for j in range(len(img_patches_val[i]))])\n",
    "gt_patches_val =  np.asarray([gt_patches_val[i][j] for i in range(len(gt_patches_val)) for j in range(len(gt_patches_val[i]))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val = features_definition_temp(img_patches_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val_scaled = scaler.transform(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_components = pca.transform(X_val_scaled)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_components.shape, X_val_scaled.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z_val = clf.predict(test_components)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_val = np.asarray([hlp.value_to_class(np.mean(gt_patches_val[i]), foreground_threshold) for i in range(len(gt_patches_val))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Y_val.shape,Z_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f1_score(Y_val, Z_val, average='binary'), accuracy_score(Y_val, Z_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(Z_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experimental features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#line detection\n",
    "#TODO: transformer ca en feature\n",
    "def proba_hough_tranform(img):\n",
    "    img = img_float_to_uint8(img)\n",
    "    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    #edges = cv2.Canny(gray,50,150,apertureSize = 3)\n",
    "    edges = ndimage.gaussian_laplace(gray, sigma=2.5)\n",
    "    features = np.zeros_like(2*img.shape[0])\n",
    "    \n",
    "    #plt.imshow(edges)\n",
    "    #plt.show()\n",
    "    minLineLength = 100\n",
    "    maxLineGap = 120\n",
    "    lines = cv2.HoughLinesP(edges,0.01,np.pi/360,100,minLineLength,maxLineGap)\n",
    "    for i in range(len(lines)):\n",
    "        #print(lines[i])\n",
    "        for x1,y1,x2,y2 in lines[i]:\n",
    "            cv2.line(img,(x1,y1),(x2,y2),(0,255,0),2)\n",
    "            \n",
    "    #cv2.imwrite('houghlines5.jpg',img)\n",
    "    plt.imshow(img)\n",
    "    plt.show()\n",
    "    \n",
    "    return features\n",
    "   \n",
    "proba_hough_tranform(imgs[3])\n",
    "plt.imshow(gt_imgs[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#kmeans algorithm for segmentation\n",
    "img = img_float_to_uint8(imgs[4])\n",
    "img=cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "vectorized = img.reshape((-1,3))\n",
    "vectorized = np.float32(vectorized)\n",
    "criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 10, 1.0)\n",
    "K = 4\n",
    "attempts=10\n",
    "ret,label,center = cv2.kmeans(vectorized,K,None,criteria,attempts,cv2.KMEANS_PP_CENTERS)\n",
    "center = np.uint8(center)\n",
    "res = center[label.flatten()]\n",
    "result_image = res.reshape((img.shape))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure_size = 15\n",
    "plt.figure(figsize=(figure_size,figure_size))\n",
    "plt.subplot(1,2,1),plt.imshow(img)\n",
    "plt.title('Original Image'), plt.xticks([]), plt.yticks([])\n",
    "plt.subplot(1,2,2),plt.imshow(result_image)\n",
    "plt.title('Segmented Image when K = %i' % K), plt.xticks([]), plt.yticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
